{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Intensity Regression using EmoLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    body{\n",
       " --vscode-font-family: \"ComicShannsMono Nerd Font\";\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "    body{\n",
    " --vscode-font-family: \"ComicShannsMono Nerd Font\";\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES: 1\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "print(f\"CUDA_VISIBLE_DEVICES: {os.environ['CUDA_VISIBLE_DEVICES']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421346c6b3af4e1d932b0f1a38d56eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# quantization_config = BitsAndBytesConfig(\n",
    "#     load_in_8bit=True,\n",
    "#     llm_int8_threshold=6.0,\n",
    "#     llm_int8_has_fp16_weight=True,\n",
    "# )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'lzw1008/Emollama-chat-7b',\n",
    "    device_map='auto',\n",
    "    cache_dir=\"cache\",\n",
    "    use_fast=False\n",
    ") \n",
    "tokenizer.pad_token_id = 0\n",
    "tokenizer.bos_token_id = 1\n",
    "tokenizer.eos_token_id = 2\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'lzw1008/Emollama-chat-7b',\n",
    "    device_map='auto',\n",
    "    # quantization_config=quantization_config,\n",
    "    # torch_type=torch.float16,\n",
    "    cache_dir=\"cache\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Story</th>\n",
       "      <th>Model</th>\n",
       "      <th>Length</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Sentences Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>When you die the afterlife is an arena where y...</td>\n",
       "      <td>3,000 years have I been fighting. Every mornin...</td>\n",
       "      <td>Human</td>\n",
       "      <td>1076</td>\n",
       "      <td>['3,000 years have I been fighting.', 'Every m...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A new law is enacted that erases soldiers memo...</td>\n",
       "      <td>“Dad, you 're on TV again !” I heard Eric 's v...</td>\n",
       "      <td>Human</td>\n",
       "      <td>1315</td>\n",
       "      <td>[\"“Dad, you 're on TV again !” I heard Eric 's...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A scientific study proves that all humans have...</td>\n",
       "      <td>When Tyler entered the ward, his daughter Vale...</td>\n",
       "      <td>Human</td>\n",
       "      <td>4420</td>\n",
       "      <td>['When Tyler entered the ward, his daughter Va...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Write a story about an elderly wizard and his ...</td>\n",
       "      <td>His body was failing. He had taken care of it ...</td>\n",
       "      <td>Human</td>\n",
       "      <td>4575</td>\n",
       "      <td>['His body was failing.', 'He had taken care o...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You have become death, destroyer of worlds.</td>\n",
       "      <td>I saw the button. It was simple, red, no words...</td>\n",
       "      <td>Human</td>\n",
       "      <td>842</td>\n",
       "      <td>['I saw the button.', 'It was simple, red, no ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Prompt  \\\n",
       "0           0  When you die the afterlife is an arena where y...   \n",
       "1           1  A new law is enacted that erases soldiers memo...   \n",
       "2           2  A scientific study proves that all humans have...   \n",
       "3           3  Write a story about an elderly wizard and his ...   \n",
       "4           4        You have become death, destroyer of worlds.   \n",
       "\n",
       "                                               Story  Model  Length  \\\n",
       "0  3,000 years have I been fighting. Every mornin...  Human    1076   \n",
       "1  “Dad, you 're on TV again !” I heard Eric 's v...  Human    1315   \n",
       "2  When Tyler entered the ward, his daughter Vale...  Human    4420   \n",
       "3  His body was failing. He had taken care of it ...  Human    4575   \n",
       "4  I saw the button. It was simple, red, no words...  Human     842   \n",
       "\n",
       "                                           Sentences  Sentences Length  \n",
       "0  ['3,000 years have I been fighting.', 'Every m...                21  \n",
       "1  [\"“Dad, you 're on TV again !” I heard Eric 's...                17  \n",
       "2  ['When Tyler entered the ward, his daughter Va...                44  \n",
       "3  ['His body was failing.', 'He had taken care o...                58  \n",
       "4  ['I saw the button.', 'It was simple, red, no ...                11  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_story_df = pd.read_csv(\"../data/tokenized_human_stories.csv\")\n",
    "model_story_df = pd.read_csv(\"../data/tokenized_model_stories.csv\")\n",
    "\n",
    "human_story_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_story_df['Sentences'] = human_story_df['Sentences'].apply(eval).tolist()\n",
    "model_story_df['Sentences'] = model_story_df['Sentences'].apply(eval).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens = 256\n",
    "generation_config = dict(\n",
    "    temperature=0.9,\n",
    "    top_k=30,\n",
    "    top_p=0.6,\n",
    "    do_sample=True,\n",
    "    num_beams=1,\n",
    "    repetition_penalty=1.2,\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_intensity_score(text) -> float:\n",
    "    pattern = r'Intensity\\s+Score:\\s*([\\d\\.]+)'\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def get_prompt(sentence_list: list, emotion: str) -> list:\n",
    "    prompt_template=f\"\"\"\\\n",
    "Task: Assign a numerical value between 0 (least {emotion}) and 1 (most {emotion}) to represent the intensity of emotion {emotion} expressed in the part of story.\\n\\\n",
    "Text: <STORY>\\n\\\n",
    "Emotion: {emotion}\\n\\\n",
    "Intensity Score:\\\n",
    "    \"\"\"\n",
    "    prompt_list = []\n",
    "    for i in range(len(sentence_list)):\n",
    "        prompt = prompt_template\n",
    "        prompt = prompt.replace(\"<STORY>\", sentence_list[i])\n",
    "        prompt_list.append(prompt)\n",
    "    return prompt_list\n",
    "\n",
    "\n",
    "model.eval()\n",
    "def inference(\n",
    "        sentence_list: list,\n",
    "        emotion_list: list,\n",
    "        batch_size: int = 1,\n",
    ") -> dict:\n",
    "    output_dict = {}\n",
    "    for emotion in emotion_list:\n",
    "        prompt_list = get_prompt(sentence_list, emotion)\n",
    "        output_dict[emotion] = []\n",
    "        for i in range(0, len(prompt_list), batch_size):\n",
    "            batch = prompt_list[i : min(i+batch_size, len(prompt_list))]\n",
    "            inputs = tokenizer(batch, return_tensors='pt', padding=True)\n",
    "            input_ids = inputs.input_ids.to(model.device)\n",
    "            attention_mask = inputs.attention_mask.to(model.device)\n",
    "            # model generate output\n",
    "            output = model.generate(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                **generation_config\n",
    "            )\n",
    "            responses = tokenizer.batch_decode(\n",
    "                output,\n",
    "                skip_special_tokens=True,\n",
    "                space_between_special_tokens=False\n",
    "            )\n",
    "            # check if the output is valid\n",
    "            for j, response in enumerate(responses):\n",
    "                intensity_score = extract_intensity_score(response)\n",
    "                output_dict[emotion].append(intensity_score)\n",
    "            \n",
    "    return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Human Stories: 100%|██████████| 96/96 [1:05:05<00:00, 40.68s/it]\n",
      "Model Stories: 100%|██████████| 576/576 [5:18:26<00:00, 33.17s/it]  \n"
     ]
    }
   ],
   "source": [
    "PLUTCHIK_EMOTION_LIST = [\n",
    "    \"anger\",\n",
    "    \"anticipation\",\n",
    "    \"joy\",\n",
    "    \"trust\",\n",
    "    \"fear\",\n",
    "    \"surprise\",\n",
    "    \"sadness\",\n",
    "    \"disgust\",\n",
    "]\n",
    "\n",
    "# iterate over the human stories\n",
    "human_emotion_score_list = []\n",
    "sentence_list = human_story_df['Sentences']\n",
    "for i in tqdm(range(len(sentence_list)), desc=\"Human Stories\"):\n",
    "    output_response = inference(\n",
    "        sentence_list[i],\n",
    "        emotion_list=PLUTCHIK_EMOTION_LIST,\n",
    "        batch_size=12,\n",
    "    )\n",
    "    human_emotion_score_list.append(output_response)\n",
    "    \n",
    "model_emotion_score_list = []\n",
    "sentence_list = model_story_df['Sentences']\n",
    "for i in tqdm(range(len(sentence_list)), desc=\"Model Stories\"):\n",
    "    output_response = inference(\n",
    "        sentence_list[i],\n",
    "        emotion_list=PLUTCHIK_EMOTION_LIST,\n",
    "        batch_size=12,\n",
    "    )\n",
    "    model_emotion_score_list.append(output_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_human_story_df = human_story_df.assign(**pd.DataFrame(human_emotion_score_list))\n",
    "scored_model_story_df = model_story_df.assign(**pd.DataFrame(model_emotion_score_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_story_emotion_scored_output = \"../data/human_story_emotion_scored.csv\"\n",
    "model_story_emotion_scored_output = \"../data/model_story_emotion_scored.csv\"\n",
    "\n",
    "scored_human_story_df.to_csv(human_story_emotion_scored_output, index=False)\n",
    "scored_model_story_df.to_csv(model_story_emotion_scored_output, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
